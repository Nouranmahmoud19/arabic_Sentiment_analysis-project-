{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e23bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noura\\OneDrive\\Desktop\\university\\arabic sentiment analysis project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from deep_translator import GoogleTranslator\n",
    "from camel_tools.utils.normalize import normalize_alef_maksura_ar, normalize_teh_marbuta_ar\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85920f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>the delivery was very very late, the estimated...</td>\n",
       "      <td>2</td>\n",
       "      <td>Judy Asal</td>\n",
       "      <td>8 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>Lots of sauce and not much beef. The photo sho...</td>\n",
       "      <td>2</td>\n",
       "      <td>Patrick bradley</td>\n",
       "      <td>15 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Oleksandr Kumeiko</td>\n",
       "      <td>a month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdallah M. Ahmed</td>\n",
       "      <td>a month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>3</td>\n",
       "      <td>Amir Rafik</td>\n",
       "      <td>a month ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                               text  rating  \\\n",
       "0  Elmenus  the delivery was very very late, the estimated...       2   \n",
       "1  Elmenus  Lots of sauce and not much beef. The photo sho...       2   \n",
       "2  Elmenus  No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...       1   \n",
       "3  Elmenus                         الاكل بارد جدا واتاخر ساعه       1   \n",
       "4  Elmenus                         الشانتونج كله لازق في بعضه       3   \n",
       "\n",
       "            reviewer   time_stamp  \n",
       "0          Judy Asal   8 days ago  \n",
       "1    Patrick bradley  15 days ago  \n",
       "2  Oleksandr Kumeiko  a month ago  \n",
       "3  Abdallah M. Ahmed  a month ago  \n",
       "4         Amir Rafik  a month ago  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\noura\\OneDrive\\Desktop\\university\\arabic sentiment analysis project\\data\\elmenus_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc79d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews before removing duplicates: 455\n",
      "Duplicate reviews: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Total reviews before removing duplicates:\", len(df))\n",
    "print(\"Duplicate reviews:\", df.duplicated(subset=['text']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be84461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate reviews: 0\n"
     ]
    }
   ],
   "source": [
    "df=df.drop_duplicates()\n",
    "print(\"Duplicate reviews:\", df.duplicated(subset=['text']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5deb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews for sentiment analysis: 454  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Reviews for sentiment analysis: {len(df)}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb79c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# def contains_english(text):\n",
    "#     return bool(re.search('[a-zA-Z]', str(text)))\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# def translate_to_arabic(text):\n",
    "#     text = str(text)\n",
    "#     if not text.strip():  \n",
    "#         return text\n",
    "#     if contains_english(text):\n",
    "#         return GoogleTranslator(source='auto', target='ar').translate(text)\n",
    "#     return text\n",
    "\n",
    "# df['text_translated'] = df['text'].progress_apply(translate_to_arabic)\n",
    "# df.to_csv(\"elmenus_reviews_translated.csv\", index=False, encoding='utf-8')\n",
    "# print(\"Translation complete. Saved as elmenus_reviews_translated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db2028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\noura\\OneDrive\\Desktop\\university\\arabic sentiment analysis project\\notebooks\\elmenus_reviews_translated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b837ead6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>text_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>the delivery was very very late, the estimated...</td>\n",
       "      <td>2</td>\n",
       "      <td>Judy Asal</td>\n",
       "      <td>8 days ago</td>\n",
       "      <td>كان التسليم متأخراً للغاية ، وكان الوقت المقدر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>Lots of sauce and not much beef. The photo sho...</td>\n",
       "      <td>2</td>\n",
       "      <td>Patrick bradley</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>الكثير من الصلصة وليس الكثير من اللحم البقري. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Oleksandr Kumeiko</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>لا قائمة السوشي !!!!!! لا قائمة السوشي !!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdallah M. Ahmed</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>3</td>\n",
       "      <td>Amir Rafik</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                               text  rating  \\\n",
       "0  Elmenus  the delivery was very very late, the estimated...       2   \n",
       "1  Elmenus  Lots of sauce and not much beef. The photo sho...       2   \n",
       "2  Elmenus  No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...       1   \n",
       "3  Elmenus                         الاكل بارد جدا واتاخر ساعه       1   \n",
       "4  Elmenus                         الشانتونج كله لازق في بعضه       3   \n",
       "\n",
       "            reviewer   time_stamp  \\\n",
       "0          Judy Asal   8 days ago   \n",
       "1    Patrick bradley  15 days ago   \n",
       "2  Oleksandr Kumeiko  a month ago   \n",
       "3  Abdallah M. Ahmed  a month ago   \n",
       "4         Amir Rafik  a month ago   \n",
       "\n",
       "                                     text_translated  \n",
       "0  كان التسليم متأخراً للغاية ، وكان الوقت المقدر...  \n",
       "1  الكثير من الصلصة وليس الكثير من اللحم البقري. ...  \n",
       "2        لا قائمة السوشي !!!!!! لا قائمة السوشي !!!!  \n",
       "3                         الاكل بارد جدا واتاخر ساعه  \n",
       "4                         الشانتونج كله لازق في بعضه  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00c5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_to_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return 'negative'\n",
    "    elif rating == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    \n",
    "df['sentiment'] = df['rating'].apply(rating_to_sentiment)\n",
    "df.to_csv(\"elmenus_reviews_with_sentiment.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866c5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r\"C:\\Users\\noura\\OneDrive\\Desktop\\university\\arabic sentiment analysis project\\notebooks\\elmenus_reviews_with_sentiment.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2f359a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>text_translated</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>the delivery was very very late, the estimated...</td>\n",
       "      <td>2</td>\n",
       "      <td>Judy Asal</td>\n",
       "      <td>8 days ago</td>\n",
       "      <td>كان التسليم متأخراً للغاية ، وكان الوقت المقدر...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>Lots of sauce and not much beef. The photo sho...</td>\n",
       "      <td>2</td>\n",
       "      <td>Patrick bradley</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>الكثير من الصلصة وليس الكثير من اللحم البقري. ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Oleksandr Kumeiko</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>لا قائمة السوشي !!!!!! لا قائمة السوشي !!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdallah M. Ahmed</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>3</td>\n",
       "      <td>Amir Rafik</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                               text  rating  \\\n",
       "0  Elmenus  the delivery was very very late, the estimated...       2   \n",
       "1  Elmenus  Lots of sauce and not much beef. The photo sho...       2   \n",
       "2  Elmenus  No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...       1   \n",
       "3  Elmenus                         الاكل بارد جدا واتاخر ساعه       1   \n",
       "4  Elmenus                         الشانتونج كله لازق في بعضه       3   \n",
       "\n",
       "            reviewer   time_stamp  \\\n",
       "0          Judy Asal   8 days ago   \n",
       "1    Patrick bradley  15 days ago   \n",
       "2  Oleksandr Kumeiko  a month ago   \n",
       "3  Abdallah M. Ahmed  a month ago   \n",
       "4         Amir Rafik  a month ago   \n",
       "\n",
       "                                     text_translated sentiment  \n",
       "0  كان التسليم متأخراً للغاية ، وكان الوقت المقدر...  negative  \n",
       "1  الكثير من الصلصة وليس الكثير من اللحم البقري. ...  negative  \n",
       "2        لا قائمة السوشي !!!!!! لا قائمة السوشي !!!!  negative  \n",
       "3                         الاكل بارد جدا واتاخر ساعه  negative  \n",
       "4                         الشانتونج كله لازق في بعضه   neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd7bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    255\n",
       "positive    121\n",
       "neutral      78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c496d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_arabic(text):\n",
    "    text=str(text)\n",
    "    text=normalize_alef_maksura_ar(text)\n",
    "    text=normalize_teh_marbuta_ar(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    return text\n",
    "\n",
    "df['text_translated'] = df['text_translated'].apply(preprocess_arabic)\n",
    "df=df[['text_translated', 'sentiment']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7fee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c0193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset=Dataset.from_pandas(train_df)\n",
    "test_dataset=Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c25caba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-mini-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name=\"asafaya/bert-mini-arabic\"\n",
    "tokenizer= AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13fdb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text_translated'], \n",
    "                    padding='max_length', truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15d5d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 363/363 [00:00<00:00, 3897.10 examples/s]\n",
      "Map: 100%|██████████| 91/91 [00:00<00:00, 7188.93 examples/s]\n",
      "Map: 100%|██████████| 363/363 [00:00<00:00, 9343.78 examples/s]\n",
      "Map: 100%|██████████| 91/91 [00:00<00:00, 8018.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset=train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset=test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "label_map={'negative': 0,\n",
    "           'neutral': 1,\n",
    "           'positive': 2}\n",
    "train_dataset = train_dataset.map(lambda x: {'label': label_map[x['sentiment']]})\n",
    "test_dataset = test_dataset.map(lambda x: {'label': label_map[x['sentiment']]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6720500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.array(['negative', 'neutral', 'positive'])\n",
    "y_train = train_df['sentiment'].values\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654dc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153614ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noura\\OneDrive\\Desktop\\university\\arabic sentiment analysis project\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\noura\\OneDrive\\Desktop\\university\\arabic sentiment analysis project\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1540: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Increased for better convergence\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    no_cuda=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6574706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {'accuracy': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c702bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b6ddc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 20%|██        | 45/225 [00:20<01:16,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8877268433570862, 'eval_accuracy': 0.6043956043956044, 'eval_f1': 0.45536655125696224, 'eval_runtime': 0.7955, 'eval_samples_per_second': 114.398, 'eval_steps_per_second': 28.914, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 40%|████      | 91/225 [00:38<00:44,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8472296595573425, 'eval_accuracy': 0.6813186813186813, 'eval_f1': 0.5984909874298364, 'eval_runtime': 0.7482, 'eval_samples_per_second': 121.626, 'eval_steps_per_second': 30.741, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 60%|██████    | 136/225 [00:55<00:33,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8285452723503113, 'eval_accuracy': 0.7142857142857143, 'eval_f1': 0.6544096928712313, 'eval_runtime': 0.6325, 'eval_samples_per_second': 143.883, 'eval_steps_per_second': 36.366, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 81%|████████  | 182/225 [01:12<00:14,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8183923363685608, 'eval_accuracy': 0.7252747252747253, 'eval_f1': 0.6704148564613681, 'eval_runtime': 0.8122, 'eval_samples_per_second': 112.041, 'eval_steps_per_second': 28.318, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 225/225 [01:29<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8153166770935059, 'eval_accuracy': 0.7362637362637363, 'eval_f1': 0.6827402248913876, 'eval_runtime': 0.8265, 'eval_samples_per_second': 110.101, 'eval_steps_per_second': 27.828, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:29<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 89.6264, 'train_samples_per_second': 20.251, 'train_steps_per_second': 2.51, 'train_loss': 0.9161754014756944, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 36.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74, F1-Score: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.2f}, F1-Score: {eval_results['eval_f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42051b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bert_mini_arabic\\\\tokenizer_config.json',\n",
       " './fine_tuned_bert_mini_arabic\\\\special_tokens_map.json',\n",
       " './fine_tuned_bert_mini_arabic\\\\vocab.txt',\n",
       " './fine_tuned_bert_mini_arabic\\\\added_tokens.json',\n",
       " './fine_tuned_bert_mini_arabic\\\\tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./fine_tuned_bert_mini_arabic')\n",
    "tokenizer.save_pretrained('./fine_tuned_bert_mini_arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1468d028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>text_translated</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>the delivery was very very late, the estimated...</td>\n",
       "      <td>2</td>\n",
       "      <td>Judy Asal</td>\n",
       "      <td>8 days ago</td>\n",
       "      <td>كان التسليم متأخراً للغاية ، وكان الوقت المقدر...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>Lots of sauce and not much beef. The photo sho...</td>\n",
       "      <td>2</td>\n",
       "      <td>Patrick bradley</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>الكثير من الصلصة وليس الكثير من اللحم البقري. ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Oleksandr Kumeiko</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>لا قائمة السوشي !!!!!! لا قائمة السوشي !!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdallah M. Ahmed</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>3</td>\n",
       "      <td>Amir Rafik</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                               text  rating  \\\n",
       "0  Elmenus  the delivery was very very late, the estimated...       2   \n",
       "1  Elmenus  Lots of sauce and not much beef. The photo sho...       2   \n",
       "2  Elmenus  No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...       1   \n",
       "3  Elmenus                         الاكل بارد جدا واتاخر ساعه       1   \n",
       "4  Elmenus                         الشانتونج كله لازق في بعضه       3   \n",
       "\n",
       "            reviewer   time_stamp  \\\n",
       "0          Judy Asal   8 days ago   \n",
       "1    Patrick bradley  15 days ago   \n",
       "2  Oleksandr Kumeiko  a month ago   \n",
       "3  Abdallah M. Ahmed  a month ago   \n",
       "4         Amir Rafik  a month ago   \n",
       "\n",
       "                                     text_translated sentiment  \n",
       "0  كان التسليم متأخراً للغاية ، وكان الوقت المقدر...  negative  \n",
       "1  الكثير من الصلصة وليس الكثير من اللحم البقري. ...  negative  \n",
       "2        لا قائمة السوشي !!!!!! لا قائمة السوشي !!!!  negative  \n",
       "3                         الاكل بارد جدا واتاخر ساعه  negative  \n",
       "4                         الشانتونج كله لازق في بعضه   neutral  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\noura\\OneDrive\\Desktop\\university\\arabic sentiment analysis project\\notebooks\\elmenus_reviews_with_sentiment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75a1a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_arabic(text):\n",
    "    text = str(text)  # Ensure text is string\n",
    "    text = normalize_alef_maksura_ar(text)\n",
    "    text = normalize_teh_marbuta_ar(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c4741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_to_sentiment(rating):\n",
    "    if pd.isna(rating):\n",
    "        return 'neutral'  # Default for missing ratings\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 'negative'\n",
    "    elif rating == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f209c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = ['text_translated', 'rating']\n",
    "\n",
    "# Preprocess text_translated and create sentiment column\n",
    "df['text_translated'] = df['text_translated'].apply(preprocess_arabic)\n",
    "df['sentiment'] = df['rating'].apply(rating_to_sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0639a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('text-classification', model='./fine_tuned_bert_mini_arabic', tokenizer='./fine_tuned_bert_mini_arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee5c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_sentiment'] = df['text_translated'].apply(lambda x: classifier(x)[0]['label'].replace('LABEL_0', 'negative').replace('LABEL_1', 'neutral').replace('LABEL_2', 'positive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31741460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>text_translated</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>the delivery was very very late, the estimated...</td>\n",
       "      <td>2</td>\n",
       "      <td>Judy Asal</td>\n",
       "      <td>8 days ago</td>\n",
       "      <td>كان التسليم متأخرا للغايه  وكان الوقت المقدر 9...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>Lots of sauce and not much beef. The photo sho...</td>\n",
       "      <td>2</td>\n",
       "      <td>Patrick bradley</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>الكثير من الصلصه وليس الكثير من اللحم البقري أ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Oleksandr Kumeiko</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>لا قائمه السوشي  لا قائمه السوشي</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdallah M. Ahmed</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الاكل بارد جدا واتاخر ساعه</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elmenus</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>3</td>\n",
       "      <td>Amir Rafik</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>الشانتونج كله لازق في بعضه</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                               text  rating  \\\n",
       "0  Elmenus  the delivery was very very late, the estimated...       2   \n",
       "1  Elmenus  Lots of sauce and not much beef. The photo sho...       2   \n",
       "2  Elmenus  No sushi menu!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ...       1   \n",
       "3  Elmenus                         الاكل بارد جدا واتاخر ساعه       1   \n",
       "4  Elmenus                         الشانتونج كله لازق في بعضه       3   \n",
       "\n",
       "            reviewer   time_stamp  \\\n",
       "0          Judy Asal   8 days ago   \n",
       "1    Patrick bradley  15 days ago   \n",
       "2  Oleksandr Kumeiko  a month ago   \n",
       "3  Abdallah M. Ahmed  a month ago   \n",
       "4         Amir Rafik  a month ago   \n",
       "\n",
       "                                     text_translated sentiment  \\\n",
       "0  كان التسليم متأخرا للغايه  وكان الوقت المقدر 9...  negative   \n",
       "1  الكثير من الصلصه وليس الكثير من اللحم البقري أ...  negative   \n",
       "2                  لا قائمه السوشي  لا قائمه السوشي   negative   \n",
       "3                         الاكل بارد جدا واتاخر ساعه  negative   \n",
       "4                         الشانتونج كله لازق في بعضه   neutral   \n",
       "\n",
       "  predicted_sentiment  \n",
       "0            negative  \n",
       "1            negative  \n",
       "2            negative  \n",
       "3            negative  \n",
       "4            negative  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "705139e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_sentiment\n",
       "negative    372\n",
       "positive     82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predicted_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0a4c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and saved 'elmenus_reviews_predicted.csv' with predictions.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('elmenus_reviews_predicted.csv', index=False)\n",
    "print(\"Created and saved 'elmenus_reviews_predicted.csv' with predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1741284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.69, F1-Score: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy = accuracy_score(df['sentiment'], df['predicted_sentiment'])\n",
    "f1 = f1_score(df['sentiment'], df['predicted_sentiment'], average='weighted', labels=['negative', 'neutral', 'positive'])\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}, F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b53b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
